{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17fa6fd7",
   "metadata": {},
   "source": [
    "Enunciado: \n",
    "El  objetivo de la pr√°ctica es simple: abordar un problema de Machine Learning realista \n",
    "siguiendo la metodolog√≠a y buenas pr√°cticas explicadas durante las clases te√≥ricas. Por \n",
    "tanto, en estas instrucciones no se especifican los pasos exactos que el alumno tiene que \n",
    "llevar a cabo para realizar esta tarea con √©xito; es parte del trabajo aplicar las t√©cnicas de \n",
    "procesamiento/transformaci√≥n de variables que mejor se adec√∫en al problema, identificar \n",
    "los  modelos  que  proporcionen  prestaciones  √≥ptimas,  las  variables  potencialmente  m√°s \n",
    "relevantes  y  la  m√©trica  adecuada  para  contrastar  los  distintos  modelos.  A√∫n  as√≠,  se \n",
    "proporciona una peque√±a gu√≠a de los pasos necesarios. Las posibilidades son amplias, as√≠ \n",
    "que  es  recomendable  abordar  una  aproximaci√≥n  incremental:  comenzar  por soluciones \n",
    "sencillas para progresivamente aumentar la complejidad de las t√©cnicas utilizadas. \n",
    " \n",
    "A diferencia de los datasets utilizados en las clases, este est√° compuesto por datos reales, \n",
    "es decir, precisa de un an√°lisis y limpieza mayores. Por el mismo motivo no se pretende \n",
    "obtener unos resultados espectaculares, es suficiente con que sean decentes; se valorar√° \n",
    "mucho  m√°s  que  el  proceso  seguido  tenga  sentido  y  no  contenga  errores  graves  de \n",
    "concepto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cef410",
   "metadata": {},
   "source": [
    "Introducci√≥n:\n",
    "Para la pr√°ctica, vamos a abordar un problema de Machine Learning en el cual, usando de base un dataset con datos de airbnb, vamos a estudiar los datos antes de seleccionar las caracter√≠sticas, prepararlos, usar profilers para observarlos mejor, y finalmente, crear nuestros modelos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd58836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ydata-profiling\n",
    "%pip install ipywidgets\n",
    "%jupyter nbextension enable --py widgetsnbextension\n",
    "%pip install setuptools\n",
    "%pip install ydata-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df46fc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nuestro primer paso ser√° cargar las librer√≠as que vamos a utilizar\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e3ac2b",
   "metadata": {},
   "source": [
    "Vamos a estudiar el dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb9b962",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_data = pd.read_csv(\"airbnb-listings-extract.csv\", sep=None, engine=\"python\", on_bad_lines=\"warn\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77b7ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_data.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31615d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_data.tail() #Mostramos la √∫ltima fila del dataset para comparar con las primeras \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99242ebc",
   "metadata": {},
   "source": [
    "A partir de estos datos, creamos un diccionario de columnas explicando qu√© hay en cada una de ellas. \n",
    " Diccionario de columnas ‚Äî Airbnb Listings \n",
    "Columna\tDescripci√≥n  \n",
    "ID\tIdentificador √∫nico del alojamiento (listing).\n",
    "Listing Url\tEnlace directo al anuncio en Airbnb.\n",
    "Scrape ID\tIdentificador de la extracci√≥n de datos (cuando se recopil√≥ la informaci√≥n).\n",
    "Last Scraped\tFecha de la √∫ltima extracci√≥n de informaci√≥n.\n",
    "Name\tT√≠tulo del anuncio.\n",
    "Summary\tResumen breve del alojamiento. \n",
    "Space\tDescripci√≥n del espacio f√≠sico del alojamiento. \n",
    "Description\tDescripci√≥n completa del anuncio. \n",
    "Experiences Offered\tIndica si el anfitri√≥n ofrece experiencias (tours, actividades, etc.). \n",
    "Neighborhood Overview\tDescripci√≥n del vecindario o zona donde se ubica el alojamiento. \n",
    "Notes\tNotas adicionales del anfitri√≥n. \n",
    "Transit\tInformaci√≥n sobre transporte p√∫blico cercano o accesos.  \n",
    "Access\tQu√© partes del alojamiento pueden usar los hu√©spedes. \n",
    "Interaction\tNivel de interacci√≥n del anfitri√≥n con los hu√©spedes.  \n",
    "House Rules\tNormas de la casa.  \n",
    "Thumbnail Url, Medium Url, Picture Url, XL Picture Url\tEnlaces a im√°genes del alojamiento en distintos tama√±os. \n",
    "Host ID\tIdentificador √∫nico del anfitri√≥n. \n",
    "Host URL\tEnlace al perfil del anfitri√≥n. \n",
    "Host Name\tNombre del anfitri√≥n. \n",
    "Host Since\tFecha en que el anfitri√≥n se uni√≥ a Airbnb.  \n",
    "Host Location\tUbicaci√≥n declarada del anfitri√≥n.  \n",
    "Host About\tDescripci√≥n personal del anfitri√≥n. \n",
    "Host Response Time\tTiempo medio de respuesta del anfitri√≥n (por ejemplo: ‚Äúwithin an hour‚Äù). \n",
    "Host Response Rate\tPorcentaje de respuestas del anfitri√≥n. \n",
    "Host Acceptance Rate\tPorcentaje de reservas aceptadas por el anfitri√≥n. \n",
    "Host Thumbnail Url, Host Picture Url\tEnlaces a la foto de perfil del anfitri√≥n. \n",
    "Host Neighbourhood\tBarrio o zona donde reside el anfitri√≥n.  \n",
    "Host Listings Count\tN√∫mero de alojamientos que tiene publicados este anfitri√≥n.  \n",
    "Host Total Listings Count\tTotal de propiedades activas del anfitri√≥n. \n",
    "Host Verifications\tM√©todos de verificaci√≥n (correo, tel√©fono, etc.).\n",
    "Street\tDirecci√≥n completa del alojamiento.  \n",
    "Neighbourhood, Neighbourhood Cleansed, Neighbourhood Group Cleansed\tNombre del barrio y su versi√≥n ‚Äúlimpia‚Äù o categorizada.\n",
    "City,   \n",
    "Market,   \n",
    "Smart Location,  \t\n",
    "Informaci√≥n geogr√°fica.  \n",
    "Country Code,  \n",
    "Pa√≠s del alojamiento.\n",
    "Latitude, Longitude\tCoordenadas geogr√°ficas.\n",
    "Property Type\tTipo de propiedad (apartamento, casa, loft, etc.).  \n",
    "Room Type\tTipo de habitaci√≥n (entera, privada, compartida).   \n",
    "Accommodates\tN√∫mero m√°ximo de hu√©spedes. \n",
    "Bathrooms, Bedrooms, Beds\tN√∫mero de ba√±os, dormitorios y camas.  \n",
    "Bed Type\tTipo de cama principal. Codificamos\n",
    "Amenities\tLista de servicios incluidos (Wi-Fi, TV, cocina, etc.). \n",
    "Square Feet\tTama√±o del alojamiento en pies cuadrados (si est√° disponible). Sacamos media redondeando \n",
    "Price, Weekly Price, Monthly Price\tPrecio por noche, semana o mes. Nos cargamos todo menos Price \n",
    "Security Deposit, Cleaning Fee\tDep√≥sito de seguridad y tarifa de limpieza. \n",
    "Guests Included\tN√∫mero de hu√©spedes incluidos en el precio base.\n",
    "Extra People\tPrecio extra por hu√©sped adicional. \n",
    "Minimum Nights, Maximum Nights\tEstancia m√≠nima y m√°xima permitida.\n",
    "Calendar Updated\t√öltima actualizaci√≥n del calendario.  \n",
    "Has Availability\tIndica si el alojamiento est√° disponible.  \n",
    "Availability 30/60/90/365\tD√≠as disponibles en los pr√≥ximos 30, 60, 90 o 365 d√≠as. \n",
    "Calendar last Scraped\tFecha de la √∫ltima actualizaci√≥n del calendario. \n",
    "Number of Reviews\tTotal de rese√±as.  \n",
    "First Review, Last Review\tFechas de la primera y √∫ltima rese√±a.  \n",
    "Review Scores Rating\tPuntuaci√≥n media global del alojamiento.\n",
    "Review Scores Accuracy, Cleanliness, Checkin, Communication, Location, Value\tSubpuntuaciones espec√≠ficas de los hu√©spedes. \n",
    "License\tN√∫mero de licencia tur√≠stica (si aplica).  \n",
    "Jurisdiction Names\tJurisdicci√≥n administrativa del alojamiento.  \n",
    "Cancellation Policy\tPol√≠tica de cancelaci√≥n (flexible, moderada, estricta, etc.).  \n",
    "Calculated host listings count\tN√∫mero de alojamientos activos del anfitri√≥n calculado autom√°ticamente.   \n",
    "Reviews per Month\tPromedio de rese√±as mensuales.  \n",
    "Geolocation\tCoordenadas combinadas (latitud, longitud). \n",
    "Features\tEtiquetas o caracter√≠sticas del anuncio (por ejemplo, ‚ÄúHost Is Superhost‚Äù).  \n",
    "\n",
    "(Extra√≠do por ChatGPT) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67beca16",
   "metadata": {},
   "source": [
    "Tambi√©n debemos usar la funci√≥n describe para ver c√≥mo son los valores de este dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda6118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe = house_data.describe(include='all').T\n",
    "print (describe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02f7147",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_data.info()\n",
    "house_data.isna().sum().sort_values(ascending=False)\n",
    "#Vemos que hay muchas columnas con muchos valores nulos, por si hace falta limpiarlos o eliminarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fcd2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calcular Q1, Q3 e IQR\n",
    "Q1 = house_data['Price'].quantile(0.25)\n",
    "Q3 = house_data['Price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# 2. definimos las barreras donde marcar los quartiles\n",
    "lower_fence = Q1 - 1.5 * IQR\n",
    "upper_fence = Q3 + 1.5 * IQR\n",
    "\n",
    "# 3. Creamos una m√°scara para identificar outliers \n",
    "outliers = house_data[\n",
    "    (house_data['Price'] < lower_fence) | (house_data['Price'] > upper_fence)\n",
    "]\n",
    "# Contar solo los valores no nulos (v√°lidos) en la columna 'Price'\n",
    "total_valores_validos = house_data['Price'].notna().sum()\n",
    "\n",
    "# Calcular el porcentaje de outliers\n",
    "porcentaje_outliers = (len(outliers) / total_valores_validos) * 100\n",
    "print(f\"Porcentaje de outliers en la columna 'Price': {porcentaje_outliers:.2f}%\")\n",
    "print(\"Dado que es un porcentaje muy alto, y perder√≠amos demasiada informaci√≥n, no eliminaremos los outliers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b1c0fc",
   "metadata": {},
   "source": [
    "Dado que hay muchos outliers, y estos representan pisos reales, no deber√≠amos eliminarlos del conjunto de datos por el cual nuestro modelo aprende. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45928ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para hacer un an√°lisis exploratorio de datos (EDA), vamos a utilizar la librer√≠a ydata-profiling\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# Crear el perfil\n",
    "profile = ProfileReport(house_data, title=\"Profiling Report\")\n",
    "\n",
    "# Mostrarlo dentro del notebook\n",
    "profile.to_notebook_iframe()\n",
    "\n",
    "# (opcional) Guardarlo como HTML\n",
    "profile.to_file(\"profiling_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb46d74",
   "metadata": {},
   "source": [
    "Aunque este primer Profiler s√≥lo nos ha permitido ver los datos para todo el dataset, y para el ejercicio s√≥lo necesitamos los datos de Madrid, ya nos permite hacer un an√°lisis algo m√°s claro, y nos permite observar cu√°les son las columnas que no van a tener ninguna correlaci√≥n. En este caso, hemos eliminado las siguientes columnas: \n",
    "'ID', 'Latitude', 'Longitude', 'Geolocation'\n",
    "dado que al tener un 100% de valores distintos entre s√≠, no nos van a permitir observar ning√∫n tipo de correlaci√≥n. \n",
    "Tambi√©n, vamos a eliminar todos los valores URL, ya que son texto largo y no aportan \n",
    "'Listing Url', 'Scrape ID', 'Thumbnail Url', 'Medium Url', 'Picture Url', 'XL Picture Url', 'Host URL', 'Host Thumbnail Url', 'Host Picture Url'\n",
    "\n",
    "Otros valores que no aportan: 'Name', 'Summary', 'Description', 'Space', 'Notes', 'Neighborhood Overview', 'Transit', 'Access', 'Interaction', 'House Rules', 'License', 'Jurisdiction Names', 'Features'\n",
    "\n",
    "Adem√°s, podemos observar que tiene una gran correlaci√≥n con 5 variables: 'Accommodates', 'Beds', 'Cleaning Fee', 'Monthly Price' y 'Weekly price', que de momento mantendremos. Hay que recordar que esta correlaci√≥n s√≥lo funciona en 1 a 1, es decir, no toma en cuenta otras variables. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd2ae5a",
   "metadata": {},
   "source": [
    "| **Atributo**                   | **Descripci√≥n**                                                               |\n",
    "| :----------------------------- | :---------------------------------------------------------------------------- |\n",
    "| *Neighbourhood Group Cleansed* | Agrupaci√≥n superior del barrio (por ejemplo, distrito o zona administrativa). |\n",
    "| *City*                         | Ciudad donde se encuentra el alojamiento.                                     |\n",
    "| *Market*                       | Mercado o √°rea geogr√°fica general (por ejemplo, ‚ÄúMadrid Area‚Äù).               |\n",
    "| *Property Type*                | Tipo de propiedad (apartamento, casa, loft, etc.).                            |\n",
    "| *Room Type*                    | Tipo de habitaci√≥n (entera, privada, compartida).                             |\n",
    "| *Accommodates*                 | N√∫mero m√°ximo de hu√©spedes.                                                   |\n",
    "| *Bathrooms*                    | N√∫mero de ba√±os o aseos.                                                      |\n",
    "| *Bedrooms*                     | N√∫mero de dormitorios.                                                        |\n",
    "| *Beds*                         | N√∫mero total de camas.                                                        |\n",
    "| *Bed Type*                     | Tipo de cama principal.                                                       |\n",
    "| *Amenities*                    | Lista de servicios disponibles (Wi-Fi, cocina, TV, etc.).                     |\n",
    "| *Square Feet*                  | Superficie del alojamiento (en pies cuadrados).                               |\n",
    "| *Price*                        | Precio por noche.                                                             |\n",
    "| *Guests Included*              | N√∫mero de hu√©spedes incluidos en el precio base.                              |\n",
    "| *Extra People*                 | Precio adicional por hu√©sped extra.                                           |\n",
    "| *Minimum Nights*               | Estancia m√≠nima permitida.                                                    |\n",
    "| *Maximum Nights*               | Estancia m√°xima permitida.                                                    |\n",
    "| *Availability 30*              | D√≠as disponibles en los pr√≥ximos 30 d√≠as.                                     |\n",
    "| *Availability 60*              | D√≠as disponibles en los pr√≥ximos 60 d√≠as.                                     |\n",
    "| *Availability 90*              | D√≠as disponibles en los pr√≥ximos 90 d√≠as.                                     |\n",
    "| *Availability 365*             | D√≠as disponibles en los pr√≥ximos 365 d√≠as.                                    |\n",
    "| *Number of Reviews*            | N√∫mero total de rese√±as recibidas.                                            |\n",
    "| *Review Scores Rating*         | Puntuaci√≥n media global del alojamiento.                                      |\n",
    "| *Review Scores Accuracy*       | Puntuaci√≥n sobre la precisi√≥n del anuncio.                                    |\n",
    "| *Review Scores Cleanliness*    | Puntuaci√≥n sobre limpieza.                                                    |\n",
    "| *Review Scores Checkin*        | Puntuaci√≥n sobre la facilidad de entrada.                                     |\n",
    "| *Review Scores Communication*  | Puntuaci√≥n sobre comunicaci√≥n con el anfitri√≥n.                               |\n",
    "| *Review Scores Location*       | Puntuaci√≥n sobre la ubicaci√≥n.                                                |\n",
    "| *Review Scores Value*          | Puntuaci√≥n sobre la relaci√≥n calidad-precio.                                  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f0e616",
   "metadata": {},
   "source": [
    "Tras eliminar las columnas que no nos han valido para nuestro estudio, y quedarnos s√≥lo con aquellas que afectan a Madrid, codificamos aquellas variables categ√≥ricas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e6e20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como parte de las buenas pr√°cticas  en ME, vamos a hacer todos los cambios en la misma celda\n",
    "#para mejorar la legibilidad\n",
    "#Eliminamos las columnas que no aportan informaci√≥n relevante para el an√°lisis\n",
    "cols_to_drop = [\n",
    "    'ID', 'Listing Url', 'Scrape ID', 'Last Scraped', 'Name', 'Summary', 'Space', 'Description',\n",
    "    'Experiences Offered', 'Neighborhood Overview', 'Notes', 'Transit', 'Access', 'Interaction',\n",
    "    'House Rules', 'Thumbnail Url', 'Medium Url', 'Picture Url', 'XL Picture Url', 'Host ID',\n",
    "    'Host URL', 'Host Name', 'Host Since', 'Host Location', 'Host About', 'Host Response Time',\n",
    "    'Host Response Rate', 'Host Acceptance Rate', 'Host Thumbnail Url', 'Host Picture Url',\n",
    "    'Host Neighbourhood', 'Host Listings Count', 'Street', 'Smart Location', 'Country Code',\n",
    "    'Calendar Updated', 'Has Availability', 'Calendar last Scraped', 'First Review', 'Last Review',\n",
    "    'License', 'Jurisdiction Names', 'Calculated host listings count', 'Reviews per Month', 'Features',\n",
    "    'Geolocation', 'Latitude', 'Longitude', 'Country', 'Host Verifications', 'Amenities', 'Weekly Price',\n",
    "    'Monthly Price', 'Extra People', 'Neighbourhood', 'zipcode'\n",
    "]\n",
    "\n",
    "house_data_clean = house_data.drop(columns=[col for col in cols_to_drop if col in house_data.columns]) \n",
    "house_data_clean.info()\n",
    "\n",
    "#Adem√°s, para mejorar la legibilidad, cambiamos la columna 'Square feet' a 'Square Meters'\n",
    "house_data_clean['Square Meters'] = house_data_clean['Square Feet'] * 0.092903\n",
    "# Eliminamos la columna original\n",
    "house_data_clean = house_data_clean.drop('Square Feet', axis=1)\n",
    "#comprobamos resultado\n",
    "house_data_clean[['Square Meters']].head()\n",
    "\n",
    "# Dado que parte de la informaci√≥n no es relevante, vamos a quedarnos con los datos pertenecientes a Madrid\n",
    "madrid_data = house_data_clean[house_data_clean['City'] == 'Madrid']\n",
    "num_madrid = madrid_data.shape[0]\n",
    "print(\"N√∫mero de anuncios en Madrid:\", num_madrid)\n",
    "porcentaje = num_madrid/14780 * 100\n",
    "print(f\"Porcentaje de anuncios en Madrid: {porcentaje:.2f}%\")\n",
    "eliminados = house_data.shape[0] - num_madrid\n",
    "print(\"N√∫mero de anuncios eliminados:\", eliminados, \"de un total de\", num_madrid + eliminados)\n",
    "#Al haber creado nuestro dataset de Madrid, eliminamos las columnas 'City' y 'State' que ya no nos hacen falta\n",
    "madrid_data = madrid_data.drop('City', axis=1)\n",
    "madrid_data = madrid_data.drop('State', axis=1)\n",
    "\n",
    "#Pasamos a codificaci√≥n de variables categ√≥ricas:\n",
    "# importar LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Crear una copia del DataFrame\n",
    "df_encoded = house_data_clean.copy()\n",
    "\n",
    "# Crear el codificador\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Creamos un codificador por cada variable categ√≥rica\n",
    "le_neigh = LabelEncoder()\n",
    "le_group = LabelEncoder()\n",
    "le_market = LabelEncoder()\n",
    "le_property = LabelEncoder()\n",
    "le_room = LabelEncoder()\n",
    "le_bed = LabelEncoder()\n",
    "le_cancel = LabelEncoder()\n",
    "\n",
    "# Aplicamos la codificaci√≥n a cada columna\n",
    "madrid_data['Neighbourhood Cleansed'] = le_neigh.fit_transform(madrid_data['Neighbourhood Cleansed'])\n",
    "madrid_data['Neighbourhood Group Cleansed'] = le_group.fit_transform(madrid_data['Neighbourhood Group Cleansed'])\n",
    "madrid_data['Market'] = le_market.fit_transform(madrid_data['Market'])\n",
    "madrid_data['Property Type'] = le_property.fit_transform(madrid_data['Property Type'])\n",
    "madrid_data['Room Type'] = le_room.fit_transform(madrid_data['Room Type'])\n",
    "madrid_data['Bed Type'] = le_bed.fit_transform(madrid_data['Bed Type'])\n",
    "madrid_data['Cancellation Policy'] = le_cancel.fit_transform(madrid_data['Cancellation Policy'])\n",
    "\n",
    "print(\"Codificaci√≥n completada correctamente.\")\n",
    "#Comprobamos que nuestras transformaciones se han realizado correctamente\n",
    "madrid_data.head().T\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#Hacemos el procesamiento de los datos para dejarlos listos para el modelado\n",
    "df = madrid_data.copy()\n",
    "#No inputamos en la columna price, ya que hay muchos valores nulos, al igual que en square meters\n",
    "#Tampoco inputamos en bedrooms, dado que entendemos que hay alojamientos que pueden no tener dormitorio \n",
    "#y disponer de un sal√≥n con sof√°-cama, por ejemplo.\n",
    "#Por √∫ltimo, la columna accommodates tiene 0 nulos y 0 valores '0', por lo que no hace falta imputar nada.\n",
    "numeric_cols = [ 'Bathrooms', 'Beds', 'Price']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    df[col] = house_data_clean[col].fillna(house_data_clean[col].mean())#A√±adimos la media ya que algunos de sus valores son muy altos\n",
    "\n",
    "#Dado que no se aceptan valores nulos, en esta variable inputamos con la moda\n",
    "imp_num = SimpleImputer(strategy='most_frequent')  # la moda\n",
    "df['Property Type'] = imp_num.fit_transform(df[['Property Type']])\n",
    "\n",
    "cols_to_impute1 = ['Host Total Listings Count' ]\n",
    "imp_zero = SimpleImputer(strategy='constant', fill_value=0)  # A√±adimos 0 donde haya valores nulos\n",
    "df[cols_to_impute1] = imp_zero.fit_transform(df[cols_to_impute1])\n",
    "\n",
    "cols_to_impute0 = ['Security Deposit', 'Cleaning Fee', 'Review Scores Rating', 'Bedrooms', 'Beds', 'Security Deposit'\n",
    ",]\n",
    "imp_zero = SimpleImputer(strategy='constant', fill_value=0)  # A√±adimos 0 donde haya valores nulos\n",
    "df[cols_to_impute0] = imp_zero.fit_transform(df[cols_to_impute0])\n",
    "\n",
    "#tambi√©n, cambiamos datos de tipo string a numeric \n",
    "df['Zipcode'] = df['Zipcode'].str.strip()  # elimina espacios o saltos de l√≠nea\n",
    "df['Zipcode'] = pd.to_numeric(df['Zipcode'], errors='coerce')  # convierte a num√©rico, NaN donde falla\n",
    "\n",
    "#al ser la variable objetivo, ponemos price como la primera columna\n",
    "cols = df.columns.tolist()\n",
    "cols.insert(0, cols.pop(cols.index('Price')))\n",
    "df = df[cols]\n",
    "df.head().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70d0a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Despu√©s de hacer este segundo acercamiento a los datos, volvemos a hacerles un profile para verlos  \n",
    "# con claridad, determinar si hemos mejorado algo y ver si hay alguna correlaci√≥n entre las variables.\n",
    "#(Entiendo que no es necesario, pero me ayuda a verlo m√°s claro))\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# Crear el perfil\n",
    "profile = ProfileReport (madrid_data, title=\"Profiling Report\")\n",
    "\n",
    "# Mostrarlo dentro del notebook\n",
    "profile.to_notebook_iframe()\n",
    "\n",
    "# (opcional) Guardarlo como HTML\n",
    "profile.to_file(\"profiling_report_madrid.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5922e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a visualizar la matriz de correlaci√≥n para ver las relaciones entre las variables num√©ricas\n",
    "import seaborn as sns\n",
    "numeric_df = df.select_dtypes(include=['number'])\n",
    "corr = numeric_df.corr()\n",
    "numeric_df.corr()\n",
    "\n",
    "# Crear la matriz de correlaci√≥n\n",
    "corr = numeric_df.corr()\n",
    "\n",
    "# Genera una m√°scara para el tri√°ngulo superior\n",
    "mask = np.zeros_like(corr, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Configura el tama√±o del gr√°fico\n",
    "f, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Dibujar heatmap\n",
    "sns.heatmap(corr, mask=mask,vmin = 0.0, vmax=1.0, center=0.5,\n",
    "            linewidths=.1, cmap=\"YlGnBu\", cbar_kws={\"shrink\": .8})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2984abdc",
   "metadata": {},
   "source": [
    "Podemos observar que la variable objetivo, Price, tiene una gran correlaci√≥n ahora con accommodates, bedrooms, beds y cleaning fee, mientras que tiene un poquito menos en bathrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ef9374",
   "metadata": {},
   "source": [
    "Vamos a utilizar primero un m√©todo embedded para seleccionar las variables que m√°s afectar√≠an a nuestro modelo. Este m√©todo utiliza Lasso como base para obtener los coeficientes de cada variable \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30983af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "df = numeric_df.dropna()\n",
    "data = df.values\n",
    "# convertimos el DataFrame al formato necesario para scikit-learn\n",
    "\n",
    " \n",
    "y = df.iloc[:, 0]      # Primera columna (variable objetivo)\n",
    "X = df.iloc[:, 1:]     # Todas las dem√°s columnas (features)\n",
    "\n",
    "feature_names = numeric_df.columns[1:]\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividimos los datos en entrenamiento y test (80 training, 20 test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state = 2)\n",
    "\n",
    "print('Datos entrenamiento: ', X_train.shape)\n",
    "print('Datos test: ', X_test.shape)\n",
    "\n",
    "# Escalamos (con los datos de train)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "XtrainScaled = scaler.transform(X_train)\n",
    "XtestScaled = scaler.transform(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "alpha_optimo = grid.best_params_['alpha']\n",
    "lasso = Lasso(alpha = alpha_optimo).fit(XtrainScaled,y_train)\n",
    "\n",
    "ytrainLasso = lasso.predict(XtrainScaled)\n",
    "ytestLasso  = lasso.predict(XtestScaled)\n",
    "mseTrainModelLasso = mean_squared_error(y_train,ytrainLasso)\n",
    "mseTestModelLasso = mean_squared_error(y_test,ytestLasso)\n",
    "\n",
    "print('MSE Modelo Lasso (train): %0.3g' % mseTrainModelLasso)\n",
    "print('MSE Modelo Lasso (test) : %0.3g' % mseTestModelLasso)\n",
    "\n",
    "print('RMSE Modelo Lasso (train): %0.3g' % np.sqrt(mseTrainModelLasso))\n",
    "print('RMSE Modelo Lasso (test) : %0.3g' % np.sqrt(mseTestModelLasso))\n",
    "\n",
    "w = lasso.coef_\n",
    "for f,wi in zip(feature_names,w):\n",
    "    print(f,wi)\n",
    "#Visualizamos la importancia de las variables seg√∫n el modelo Lasso\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "coef_df = pd.DataFrame({'Feature': X.columns, 'Coefficient': lasso.coef_})\n",
    "coef_df = coef_df[coef_df['Coefficient'] != 0].sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(coef_df['Feature'], coef_df['Coefficient'])\n",
    "plt.xlabel('Peso del coeficiente')\n",
    "plt.ylabel('Variable')\n",
    "plt.title('Importancia de las variables seg√∫n Lasso')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139aef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para conseguir un mejor control del c√≥digo, vamos a hacerlo todo en una misma celda\n",
    "# Importar librer√≠as\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# =============================================\n",
    "# 1 Cargar y preparar los datos\n",
    "# =============================================\n",
    "\n",
    "# Variables seleccionadas\n",
    "selected_features = ['Bedrooms', 'Guests Included', 'Square Meters', 'Review Scores Rating', 'Bathrooms',\n",
    "                               'Review Scores Cleanliness', 'Availability 60', 'Host Total Listings Count', \n",
    "                               'Property Type', 'Room Type', 'Review Scores Communication', 'Zipcode', 'Number of Reviews', \n",
    "                               'Neighbourhood Group Cleansed' ]\n",
    "\n",
    "\n",
    "# Eliminamos filas con NaN en esas columnas y en la variable objetivo\n",
    "df_clean = numeric_df.dropna(subset=selected_features + ['Price'])\n",
    "\n",
    "# Definimos X e y con nombres de columna\n",
    "X = df_clean[selected_features].values\n",
    "y = df_clean['Price'].values\n",
    "\n",
    "# Divisi√≥n entrenamiento/test. aunque en clase hemos visto que es mejor estratificar la divisi√≥n, \n",
    "# es posible debido a que la variable objetivo es continua\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=2, shuffle=True, \n",
    ")\n",
    "\n",
    "print(\"Datos entrenamiento:\", X_train.shape)\n",
    "print(\"Datos test:\", X_test.shape)\n",
    "# =============================================\n",
    "# 3Ô∏è Escalado de datos\n",
    "# =============================================\n",
    "\n",
    "# Escalado\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "XtrainScaled = scaler.transform(X_train)\n",
    "XtestScaled = scaler.transform(X_test)\n",
    "\n",
    "# =============================================\n",
    "# 4Ô∏è B√∫squeda del mejor alpha con GridSearchCV\n",
    "# =============================================\n",
    "\n",
    "alpha_vector = np.logspace(-1,10,20, 50) # vector de valores de alpha a probar\n",
    "param_grid = {'alpha': alpha_vector } \n",
    "grid = GridSearchCV(Lasso(max_iter=10000), scoring= 'neg_mean_squared_error', param_grid=param_grid, cv = 3, verbose=2) \n",
    "grid.fit(XtrainScaled, y_train) \n",
    "\n",
    "\n",
    "print(\"\\nüîç Mejor alpha encontrado:\", grid.best_params_['alpha'])\n",
    "print(\"üìâ Mejor score (MSE medio):\", -grid.best_score_)\n",
    "\n",
    "# Visualizar la curva de MSE en funci√≥n de alpha\n",
    "#-1 porque es negado\n",
    "scores = -1*np.array(grid.cv_results_['mean_test_score'])\n",
    "plt.semilogx(alpha_vector,scores,'-o')\n",
    "plt.xlabel('alpha',fontsize=16)\n",
    "plt.ylabel('5-Fold MSE')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# 5Ô∏è Entrenamiento final con alpha √≥ptimo\n",
    "# =============================================\n",
    "\n",
    "\n",
    "alpha_optimo = grid.best_params_['alpha']\n",
    "lasso = Lasso(alpha = alpha_optimo).fit(XtrainScaled,y_train)\n",
    "\n",
    "ytrainLasso = lasso.predict(XtrainScaled)\n",
    "ytestLasso  = lasso.predict(XtestScaled)\n",
    "mseTrainModelLasso = mean_squared_error(y_train,ytrainLasso)\n",
    "mseTestModelLasso = mean_squared_error(y_test,ytestLasso)\n",
    "\n",
    "print('MSE Modelo Lasso (train): %0.3g' % mseTrainModelLasso)\n",
    "print('MSE Modelo Lasso (test) : %0.3g' % mseTestModelLasso)\n",
    "\n",
    "print('RMSE Modelo Lasso (train): %0.3g' % np.sqrt(mseTrainModelLasso))\n",
    "print('RMSE Modelo Lasso (test) : %0.3g' % np.sqrt(mseTestModelLasso))\n",
    "\n",
    "w = lasso.coef_\n",
    "for f,wi in zip(selected_features,w):\n",
    "    print(f,wi)\n",
    "\n",
    "\n",
    "# =============================================\n",
    "#  Visualizar importancia de variables\n",
    "# =============================================\n",
    "print('MSE Modelo Lasso (train): {:.2f}'.format(mseTrainModelLasso))\n",
    "print('MSE Modelo Lasso (test) : {:.2f}'.format(mseTestModelLasso))\n",
    "print('RMSE Modelo Lasso (train): %0.3g' % np.sqrt(mseTrainModelLasso))\n",
    "print('RMSE Modelo Lasso (test) : %0.3g' % np.sqrt(mseTestModelLasso))\n",
    "\n",
    "# --- 2. Preparaci√≥n de la Importancia de Variables para Lasso (Corregida) ---\n",
    "\n",
    "# Importancia: Para Lasso, la importancia es el valor absoluto del coeficiente.\n",
    "importances = np.abs(lasso.coef_)\n",
    "\n",
    "# Normalizaci√≥n: Se divide por el valor m√°ximo (opcional, pero ayuda a la visualizaci√≥n).\n",
    "# Solo se normaliza si el m√°ximo no es cero, para evitar la divisi√≥n por cero.\n",
    "if np.max(importances) > 0:\n",
    "    importances = importances / np.max(importances)\n",
    "else:\n",
    "    # Si todas son cero (modelo sin funcionalidad), usa el array sin normalizar.\n",
    "    pass \n",
    "\n",
    "# Ordenaci√≥n: Obtener los √≠ndices de mayor a menor importancia.\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# CONVERSI√ìN CRUCIAL: Convertir la lista 'selected_features' a un array de NumPy\n",
    "# para que acepte la indexaci√≥n m√∫ltiple.\n",
    "selected_features_array = np.array(selected_features)\n",
    "\n",
    "# --- 3. Generaci√≥n de la Gr√°fica ---\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"Importancia de Caracter√≠sticas (Lasso Coeficientes Absolutos)\")\n",
    "\n",
    "# Graficar las barras (la longitud de X_train.shape[1] puede ser incorrecta aqu√≠; \n",
    "# usamos el n√∫mero de coeficientes para consistencia con 'selected_features')\n",
    "num_features = len(importances)\n",
    "plt.barh(range(num_features), importances[indices])\n",
    "\n",
    "# CORRECCI√ìN: Usar el array de NumPy (selected_features_array) para los nombres\n",
    "plt.yticks(range(num_features), selected_features_array[indices])\n",
    "\n",
    "plt.xlabel(\"Valor Absoluto Normalizado del Coeficiente\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08dedc4",
   "metadata": {},
   "source": [
    "**Evaluaci√≥n del modelo**\n",
    "\n",
    "Con el modelo Lasso, hemos conseguido un modelo en el cual nuestro error RMSE es de 38.9 euros en Train, y 44 en Test, es decir, las predicciones no se alejan mucho una de la otra, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a107debc",
   "metadata": {},
   "source": [
    "**Modelo Ridge**\n",
    "\n",
    "dado que hemos conseguido realizar un buen modelo con Lasso, vamos a tratar de usar los mismos datos para hacer un modelo usando Ridge\n",
    "Ridge busca usar todas las variables que haya disponibles, siempre que los coeficientes resultantes no sean demasiado grandes, penalizando aquellos que sean demasiado grandes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fee848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "#  Importamos la librer√≠a Ridge\n",
    "# =============================================\n",
    "from sklearn.linear_model import Ridge\n",
    "# =============================================\n",
    "#  Definimos X e y con nombres de columna\n",
    "# =============================================\n",
    "X = df_clean[selected_features].values\n",
    "y = df_clean['Price'].values\n",
    "# =============================================\n",
    "# Divisi√≥n entrenamiento/test. aunque en clase hemos visto que es mejor estratificar la divisi√≥n, \n",
    "# es imposible  debido a que la variable objetivo es continua\n",
    "# =============================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=2, shuffle=True)\n",
    "\n",
    "# =============================================\n",
    "# Entrenamos el modelo y sacamos sus coeficientes\n",
    "# =============================================\n",
    "alpha = alpha_optimo\n",
    "ridge = Ridge(alpha=alpha_optimo).fit(X_train,y_train)\n",
    "w = ridge.coef_\n",
    "norm_w2 = np.dot(w,w.T)\n",
    "\n",
    "# predicci√≥n\n",
    "y_hat = ridge.predict(X_test)\n",
    "\n",
    "# =============================================\n",
    "# Evaluaci√≥n del modelo\n",
    "# =============================================\n",
    "# 1. Crear el DataFrame de Coeficientes de Ridge\n",
    "# Usamos los coeficientes del modelo 'ridge' y los nombres de 'selected_features'.\n",
    "coef_ridge_df = pd.DataFrame({\n",
    "    'Feature': selected_features,\n",
    "    'Coeficiente': ridge.coef_\n",
    "})\n",
    "\n",
    "# 2. Ordenar por el valor absoluto del coeficiente (para que las barras m√°s importantes queden arriba)\n",
    "coef_ridge_df['Abs_Coef'] = np.abs(coef_ridge_df['Coeficiente'])\n",
    "coef_ridge_df = coef_ridge_df.sort_values(by='Abs_Coef', ascending=False)\n",
    "\n",
    "# 3. Generar el Gr√°fico de Barras Horizontal\n",
    "plt.figure(figsize=(12, len(coef_ridge_df) * 0.4)) # Ajustar el tama√±o para que sea legible\n",
    "plt.barh(coef_ridge_df['Feature'], coef_ridge_df['Coeficiente'], color='skyblue')\n",
    "plt.xlabel('Valor del Coeficiente Ridge')\n",
    "plt.title('Influencia de Variables en el Modelo Ridge')\n",
    "\n",
    "# A√±ade una l√≠nea vertical en cero para distinguir f√°cilmente los impactos positivos y negativos\n",
    "plt.axvline(0, color='gray', linestyle='--') \n",
    "plt.gca().invert_yaxis() # Pone la caracter√≠stica m√°s importante (la de mayor magnitud) arriba\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- C√°lculo del MSE para su evaluaci√≥n---\n",
    "# --- 1. Predicciones ---\n",
    "y_train_hat = ridge.predict(X_train)\n",
    "y_test_hat = ridge.predict(X_test)\n",
    "mseTrainModelRidge = mean_squared_error(y_train, y_train_hat)\n",
    "mseTestModelRidge = mean_squared_error(y_test, y_test_hat)\n",
    "\n",
    "# --- 3. Impresi√≥n de Resultados ---\n",
    "print(\"--- Evaluaci√≥n del Modelo Ridge ---\")\n",
    "print('MSE Modelo Ridge (train): {:.2f}'.format(mseTrainModelRidge))\n",
    "print('MSE Modelo Ridge (test) : {:.2f}'.format(mseTestModelRidge))\n",
    "\n",
    "print('RMSE Modelo Ridge (train): {:.3f}'.format(np.sqrt(mseTrainModelRidge)))\n",
    "print('RMSE Modelo Ridge (test) : {:.3f}'.format(np.sqrt(mseTestModelRidge)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa134ea",
   "metadata": {},
   "source": [
    "**Conclusiones Ridge**\n",
    "Observamos que el modelo Ridge tiene un error similar al de Lasso utilizando las mismas variables, en el cual el error medio es de unos 38 euros en Train y 43 euros en test, muy similar a lo que hemos obtenido en Lasso (Lo cual tiene sentido, ya que hemos utilizado las mismas variables para este modelo )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8e7def",
   "metadata": {},
   "source": [
    "**Modelo Random Forest**\n",
    "Vamos a utilizar tambi√©n  el m√©todo Random forest, dado que este puede, por medio de √°rboles creados aleatoriamente, capturar interacciones complejas y suele ser m√°s preciso.\n",
    "Este modelo  se basa en los √°rboles de decisi√≥n, y consiste en lo siguiente: \n",
    "Random forest crea m√∫ltiples √°rboles de decisi√≥n independientes, que entrena con el m√©todo bagging. Finalmente combina los resultados de todos los √°rboles, tomando el promedio de las salidas de todos los √°rboles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f298b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ahora vamos a probar con RandomForestRegressor\n",
    "#Primero importamos la librer√≠a\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#Dado que antes usamos \n",
    "maxDepth = range(1,30)\n",
    "feature_names = df.drop('Price', axis=1).columns.to_list()\n",
    "tuned_parameters = {'max_depth': maxDepth}\n",
    "# Definimos X e y para Random Forest (todas las columnas excepto 'Price' como X, y 'Price' como y)\n",
    "X = df.drop('Price', axis=1).values\n",
    "y = df['Price'].values\n",
    "# Divisi√≥n entrenamiento/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2, shuffle=True)\n",
    "print(\"Datos entrenamiento:\", X_train.shape)\n",
    "print(\"Datos test:\", X_test.shape)\n",
    "# B√∫squeda de hiperpar√°metros con GridSearchCV\n",
    "grid = GridSearchCV(RandomForestRegressor(random_state=0, n_estimators=500, max_features='sqrt',min_samples_leaf=10), param_grid=tuned_parameters,cv=5, verbose=2)\n",
    "grid.fit(X_train, y_train)\n",
    "#Aplicamos cv 5 porque hemos probado con cv 10 y los resultados ten√≠an un overfitting muy grande\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid.best_score_))\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "\n",
    "scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "plt.plot(maxDepth,scores,'-o')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('5-fold ACC')\n",
    "\n",
    "plt.show()\n",
    "maxDepthOptimo = grid.best_params_['max_depth']\n",
    "randomForest = RandomForestRegressor(max_depth=maxDepthOptimo,n_estimators=500,max_features='sqrt',min_samples_leaf=10).fit(X_train,y_train)\n",
    "print(\"Train: \",randomForest.score(X_train,y_train))\n",
    "print(\"Test: \",randomForest.score(X_test,y_test))\n",
    "importances = randomForest.feature_importances_\n",
    "importances = importances / np.max(importances)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Convertir la lista a array de NumPy\n",
    "feature_names_array = np.array(feature_names) \n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"Importancia de Caracter√≠sticas (Random Forest)\")\n",
    "plt.barh(range(X_train.shape[1]), importances[indices])\n",
    "\n",
    "# Usar el array de NumPy (feature_names_array)\n",
    "plt.yticks(range(X_train.shape[1]), feature_names_array[indices])\n",
    "\n",
    "plt.xlabel(\"Importancia Normalizada\")\n",
    "plt.show()\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Predicciones en el conjunto de entrenamiento\n",
    "y_train_hat = randomForest.predict(X_train) \n",
    "# Predicciones en el conjunto de prueba\n",
    "y_test_hat = randomForest.predict(X_test)\n",
    "\n",
    "# --- 2. C√°lculo de MSE ---\n",
    "mseTrainModelRF = mean_squared_error(y_train, y_train_hat)\n",
    "mseTestModelRF = mean_squared_error(y_test, y_test_hat)\n",
    "\n",
    "# --- 3. Impresi√≥n de Resultados ---\n",
    "print(\"--- Evaluaci√≥n de Errores (Random Forest) ---\")\n",
    "print('MSE (Train): {:.3f}'.format(mseTrainModelRF))\n",
    "print('MSE (Test) : {:.3f}'.format(mseTestModelRF))\n",
    "print('-----------------------------------------')\n",
    "print('RMSE (Train): {:.3f}'.format(np.sqrt(mseTrainModelRF)))\n",
    "print('RMSE (Test) : {:.3f}'.format(np.sqrt(mseTestModelRF)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff7e4ad",
   "metadata": {},
   "source": [
    "Como vemos, este modelo tiene un mejor desempe√±o que los anteriores, con un MSE y RMSE m√°s bajos en ambos conjuntos, lo que indica una mejor capacidad predictiva y menor error en las predicciones.\n",
    "\n",
    "Como siempre, nuestro indicador ha sido el RMSE, ya que nos permite explicar y materializar nuestras explicaciones, que en este caso nos da una diferencia de 37.07 euros en Train, y 44.146 euros en test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de814681",
   "metadata": {},
   "source": [
    "**Conclusi√≥n**  \n",
    "Para terminar nuestra pr√°ctica, hemos creado 3 modelos de machine learning utilizando los m√©todos Lasso, Ridge y Random Forest a partir de un dataset de Airbnb. Tras observar los datos existentes, su tipo, y otras caracter√≠sticas del dataset, hemos limpiado los datos para dejarlos operables para trabajar (es decir, hemos codificado las variables categ√≥ricas como variables discretas, hemos convertido a INT aquellos datos que eran STRING, y hemos inputado aquellos resultados que ha sido necesario, ya fuera con valores como la moda o la media)\n",
    "\n",
    "Adem√°s, para observar mejor los datos, hemos utilizado dos profilers, uno previo al procesado de datos, y uno posterior, para tener una idea clara de c√≥mo son nuestros datos despu√©s de procesarlos\n",
    "Tras eso, hemos creado los modelos usando Lasso, Ridge y Random Forest, 3 m√©todos que han dado resultados muy similares, dado que las caracter√≠sticas utilizadas para entrenar los modelos eran las mismas (si bien en Lasso y Ridge hemos quitado aquellas que el modelo embedded con Lasso ha considerado que tienen un coeficiente de 0). \n",
    "\n",
    "En conjunto, los tres modelos mostraron un rendimiento equilibrado y coherente, lo cual nos confirma la eficacia del trabajo "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
